# 人工智慧第十一週筆記
## 神經網路:  
 將正確答案與現在的答案之間的差距縮短，愈小愈好。  
 模仿人的神經元與神經元之間的連線，透過計算神經衝動，還獲取最優解，神經衝動強度愈高，則數值愈高，因此神經網路程式不需要去模擬「細胞膜、粒線體、核醣體」等等複雜的結構，因為學電腦的人可以透過抽象化，將神經細胞結構簡化。

## 梯度下降法
 深度學習 (Deep Learning) 是人工智慧領域當紅的技術，說穿了其實就是原本的《神經網路》(Neural Network) ，不過由於加上了一些新的模型 (像是捲積神經網路 CNN, 循環神經網路 RNN 與生成對抗網路 GAN)，還有在神經網路的層數上加深很多，從以往的 3-4 層，提升到了十幾層，甚至上百層，於是我們給這些新一代的《神經網路》技術一個統稱，那就是《深度學習》。   
 雖然《深度學習》的神經網路層數變多了，《網路模型》也多了一些，但是背後的學習算法和運作原理並沒有多大改變，仍然是以《梯度下降》(Gradient Descendent) 和《反傳遞算法》(Back Propagation) 為主。  
 (梯度:斜率最大的方向)  
 利用微積分計算梯度，並朝坡度最陡的位置向下移動。