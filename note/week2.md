# 人工智慧第二週筆記
## 人工智慧的方法
* 比對法  
 記錄問題與答案配對後，直接從表格內查出。
---
* 推理法  
 讓電腦根據先寫好的規則進行推論。
---
* 搜尋法  
 對所有可能的結果進行系統式列舉，看是否有相符的答案。
---
* 統計法  
 根據統計資訊，找出最有可能的結果。  
 可與推理搜尋一起使用。
---
* 優化法  
 給所有可能打分數，並選出分數最高者。  
 例如:爬山演算法、遺傳演算法、期望-最大化演算法、神經網路
---
## 優化法

* 爬山演算法  
 往附近較高處移動。  
 遇到山脊: 用微積分算梯度。  
 遇到多個山峰: 不一定會到最高處。  
 在多數情況下都能使用。
---
* 神經網路:  
 將正確答案與現在的答案之間的差距縮短，愈小愈好。  
 模仿人的神經元與神經元之間的連線，透過計算神經衝動，還獲取最優解，神經衝動強度愈高，則數值愈高。
---
* 梯度下降法:  
 (梯度:斜率最大的方向)  
 利用微積分計算梯度，並朝坡度最陡的位置向下移動。
---
* 反傳遞演算法:  
 利用微積分的鏈鎖規則，由後一層推算前一層的梯度，進而調整前一層的參數。
---
* 深度學習:  
 使用多層感知器外也使用了:  
 1.  卷積神經網路(CNN):  
 常用來辨認影像。  
 卷積層(CONV):  
 是一種遮罩函數，檢查有無符合遮罩的點。  
 池化層(Pool):  
 則是取最大值，可用來降低維度。  
 ReLu層:  
 則是一種開關，讓高於門檻的訊號通過。  
 2.  循環神經網路(RNN, LSTM):  
 最常用來處理語言，有循環的神經網路，可用來儲存一些狀態，相同輸出結果不一定相同(和目前狀態有關)。  
 3.  生成對抗網路(GAN):  
 採用「偽造者與鑑賞者」的對抗方式，讓兩者在對抗過程中增強。  
 4.  強化學習機制:  
 利用獎勵及扣分機制進行學習。